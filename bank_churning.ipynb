{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bank Churning\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Useless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = data.drop(columns = ['RowNumber','CustomerId', 'Surname' ])\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize CreditScore, Age, Balance, EstimatedSalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# clean['CreditScore'] = MinMaxScaler().fit_transform(np.array(clean['CreditScore']).reshape(-1,1))\n",
    "# clean['Age'] = MinMaxScaler().fit_transform(np.array(clean['Age']).reshape(-1,1))\n",
    "# clean['Balance'] = MinMaxScaler().fit_transform(np.array(clean['Balance']).reshape(-1,1))\n",
    "# clean['EstimatedSalary'] = MinMaxScaler().fit_transform(np.array(clean['EstimatedSalary']).reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clean.iloc[:-1, :-1].values\n",
    "y = clean.iloc[:-1, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Gender Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "l = LabelEncoder()\n",
    "x[:,2] = l.fit_transform(x[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encode Geography Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build ANN\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "#input layer\n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
    "\n",
    "#hidden layers\n",
    "ann.add(tf.keras.layers.Dense(units = 4, activation = 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 12, activation = 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 8, activation = 'relu'))\n",
    "\n",
    "\n",
    "#output layer\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training ANN\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Model on the Churning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "500/500 [==============================] - 4s 6ms/step - loss: 0.6193 - accuracy: 0.7852 - val_loss: 0.5800 - val_accuracy: 0.7885\n",
      "Epoch 2/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5453 - accuracy: 0.7982 - val_loss: 0.5367 - val_accuracy: 0.7885\n",
      "Epoch 3/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.5135 - accuracy: 0.7982 - val_loss: 0.5166 - val_accuracy: 0.7885\n",
      "Epoch 4/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4976 - accuracy: 0.7982 - val_loss: 0.5055 - val_accuracy: 0.7885\n",
      "Epoch 5/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4880 - accuracy: 0.7982 - val_loss: 0.4986 - val_accuracy: 0.7885\n",
      "Epoch 6/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4812 - accuracy: 0.7982 - val_loss: 0.4927 - val_accuracy: 0.7885\n",
      "Epoch 7/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4754 - accuracy: 0.7982 - val_loss: 0.4875 - val_accuracy: 0.7885\n",
      "Epoch 8/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4700 - accuracy: 0.7982 - val_loss: 0.4826 - val_accuracy: 0.7885\n",
      "Epoch 9/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4649 - accuracy: 0.7982 - val_loss: 0.4781 - val_accuracy: 0.7885\n",
      "Epoch 10/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4601 - accuracy: 0.7982 - val_loss: 0.4737 - val_accuracy: 0.7885\n",
      "Epoch 11/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4558 - accuracy: 0.7982 - val_loss: 0.4697 - val_accuracy: 0.7885\n",
      "Epoch 12/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4518 - accuracy: 0.7982 - val_loss: 0.4659 - val_accuracy: 0.7885\n",
      "Epoch 13/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4485 - accuracy: 0.7982 - val_loss: 0.4635 - val_accuracy: 0.7885\n",
      "Epoch 14/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4454 - accuracy: 0.7982 - val_loss: 0.4603 - val_accuracy: 0.7885\n",
      "Epoch 15/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4429 - accuracy: 0.7982 - val_loss: 0.4580 - val_accuracy: 0.7885\n",
      "Epoch 16/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4406 - accuracy: 0.7982 - val_loss: 0.4562 - val_accuracy: 0.7885\n",
      "Epoch 17/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4384 - accuracy: 0.7982 - val_loss: 0.4547 - val_accuracy: 0.7885\n",
      "Epoch 18/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4365 - accuracy: 0.7982 - val_loss: 0.4530 - val_accuracy: 0.7885\n",
      "Epoch 19/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4348 - accuracy: 0.7982 - val_loss: 0.4521 - val_accuracy: 0.7885\n",
      "Epoch 20/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4334 - accuracy: 0.7982 - val_loss: 0.4512 - val_accuracy: 0.7885\n",
      "Epoch 21/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4322 - accuracy: 0.7982 - val_loss: 0.4497 - val_accuracy: 0.7885\n",
      "Epoch 22/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4306 - accuracy: 0.7982 - val_loss: 0.4496 - val_accuracy: 0.7885\n",
      "Epoch 23/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4296 - accuracy: 0.7982 - val_loss: 0.4480 - val_accuracy: 0.7885\n",
      "Epoch 24/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4283 - accuracy: 0.7982 - val_loss: 0.4477 - val_accuracy: 0.7885\n",
      "Epoch 25/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4274 - accuracy: 0.7982 - val_loss: 0.4464 - val_accuracy: 0.7885\n",
      "Epoch 26/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4263 - accuracy: 0.7982 - val_loss: 0.4453 - val_accuracy: 0.7885\n",
      "Epoch 27/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4253 - accuracy: 0.7997 - val_loss: 0.4451 - val_accuracy: 0.7885\n",
      "Epoch 28/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4244 - accuracy: 0.8011 - val_loss: 0.4435 - val_accuracy: 0.7880\n",
      "Epoch 29/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4235 - accuracy: 0.8044 - val_loss: 0.4437 - val_accuracy: 0.7885\n",
      "Epoch 30/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4228 - accuracy: 0.8045 - val_loss: 0.4425 - val_accuracy: 0.7890\n",
      "Epoch 31/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4219 - accuracy: 0.8081 - val_loss: 0.4423 - val_accuracy: 0.7900\n",
      "Epoch 32/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4211 - accuracy: 0.8112 - val_loss: 0.4411 - val_accuracy: 0.7905\n",
      "Epoch 33/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4202 - accuracy: 0.8131 - val_loss: 0.4398 - val_accuracy: 0.7925\n",
      "Epoch 34/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4197 - accuracy: 0.8149 - val_loss: 0.4396 - val_accuracy: 0.7925\n",
      "Epoch 35/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4187 - accuracy: 0.8164 - val_loss: 0.4387 - val_accuracy: 0.7930\n",
      "Epoch 36/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4181 - accuracy: 0.8166 - val_loss: 0.4387 - val_accuracy: 0.7955\n",
      "Epoch 37/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4173 - accuracy: 0.8176 - val_loss: 0.4385 - val_accuracy: 0.7960\n",
      "Epoch 38/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4166 - accuracy: 0.8187 - val_loss: 0.4385 - val_accuracy: 0.7965\n",
      "Epoch 39/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4159 - accuracy: 0.8197 - val_loss: 0.4368 - val_accuracy: 0.7965\n",
      "Epoch 40/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4152 - accuracy: 0.8209 - val_loss: 0.4361 - val_accuracy: 0.7965\n",
      "Epoch 41/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4145 - accuracy: 0.8214 - val_loss: 0.4356 - val_accuracy: 0.7995\n",
      "Epoch 42/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4138 - accuracy: 0.8221 - val_loss: 0.4347 - val_accuracy: 0.7975\n",
      "Epoch 43/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4131 - accuracy: 0.8220 - val_loss: 0.4340 - val_accuracy: 0.7980\n",
      "Epoch 44/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4123 - accuracy: 0.8227 - val_loss: 0.4330 - val_accuracy: 0.8005\n",
      "Epoch 45/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4117 - accuracy: 0.8232 - val_loss: 0.4332 - val_accuracy: 0.7990\n",
      "Epoch 46/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4109 - accuracy: 0.8237 - val_loss: 0.4323 - val_accuracy: 0.8015\n",
      "Epoch 47/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4101 - accuracy: 0.8239 - val_loss: 0.4325 - val_accuracy: 0.8005\n",
      "Epoch 48/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4096 - accuracy: 0.8239 - val_loss: 0.4312 - val_accuracy: 0.8020\n",
      "Epoch 49/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4089 - accuracy: 0.8245 - val_loss: 0.4307 - val_accuracy: 0.8020\n",
      "Epoch 50/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4080 - accuracy: 0.8244 - val_loss: 0.4308 - val_accuracy: 0.8015\n",
      "Epoch 51/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4074 - accuracy: 0.8251 - val_loss: 0.4296 - val_accuracy: 0.8015\n",
      "Epoch 52/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4067 - accuracy: 0.8256 - val_loss: 0.4290 - val_accuracy: 0.8020\n",
      "Epoch 53/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4059 - accuracy: 0.8256 - val_loss: 0.4289 - val_accuracy: 0.8000\n",
      "Epoch 54/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4052 - accuracy: 0.8262 - val_loss: 0.4274 - val_accuracy: 0.8025\n",
      "Epoch 55/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4044 - accuracy: 0.8260 - val_loss: 0.4274 - val_accuracy: 0.8005\n",
      "Epoch 56/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4037 - accuracy: 0.8280 - val_loss: 0.4267 - val_accuracy: 0.8015\n",
      "Epoch 57/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.4030 - accuracy: 0.8287 - val_loss: 0.4263 - val_accuracy: 0.8045\n",
      "Epoch 58/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4022 - accuracy: 0.8291 - val_loss: 0.4248 - val_accuracy: 0.8090\n",
      "Epoch 59/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4016 - accuracy: 0.8312 - val_loss: 0.4247 - val_accuracy: 0.8075\n",
      "Epoch 60/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4007 - accuracy: 0.8327 - val_loss: 0.4253 - val_accuracy: 0.8065\n",
      "Epoch 61/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.4000 - accuracy: 0.8326 - val_loss: 0.4244 - val_accuracy: 0.8090\n",
      "Epoch 62/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3992 - accuracy: 0.8320 - val_loss: 0.4227 - val_accuracy: 0.8095\n",
      "Epoch 63/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3985 - accuracy: 0.8344 - val_loss: 0.4228 - val_accuracy: 0.8110\n",
      "Epoch 64/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3976 - accuracy: 0.8341 - val_loss: 0.4213 - val_accuracy: 0.8105\n",
      "Epoch 65/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3970 - accuracy: 0.8349 - val_loss: 0.4212 - val_accuracy: 0.8125\n",
      "Epoch 66/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3962 - accuracy: 0.8346 - val_loss: 0.4204 - val_accuracy: 0.8125\n",
      "Epoch 67/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3954 - accuracy: 0.8351 - val_loss: 0.4202 - val_accuracy: 0.8155\n",
      "Epoch 68/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3946 - accuracy: 0.8357 - val_loss: 0.4199 - val_accuracy: 0.8150\n",
      "Epoch 69/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3938 - accuracy: 0.8365 - val_loss: 0.4188 - val_accuracy: 0.8150\n",
      "Epoch 70/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3929 - accuracy: 0.8367 - val_loss: 0.4176 - val_accuracy: 0.8155\n",
      "Epoch 71/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3922 - accuracy: 0.8367 - val_loss: 0.4168 - val_accuracy: 0.8165\n",
      "Epoch 72/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3914 - accuracy: 0.8376 - val_loss: 0.4177 - val_accuracy: 0.8155\n",
      "Epoch 73/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3907 - accuracy: 0.8377 - val_loss: 0.4162 - val_accuracy: 0.8180\n",
      "Epoch 74/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3899 - accuracy: 0.8380 - val_loss: 0.4151 - val_accuracy: 0.8180\n",
      "Epoch 75/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3891 - accuracy: 0.8380 - val_loss: 0.4152 - val_accuracy: 0.8160\n",
      "Epoch 76/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3883 - accuracy: 0.8372 - val_loss: 0.4131 - val_accuracy: 0.8180\n",
      "Epoch 77/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3875 - accuracy: 0.8382 - val_loss: 0.4124 - val_accuracy: 0.8185\n",
      "Epoch 78/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3866 - accuracy: 0.8391 - val_loss: 0.4122 - val_accuracy: 0.8180\n",
      "Epoch 79/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3858 - accuracy: 0.8405 - val_loss: 0.4116 - val_accuracy: 0.8175\n",
      "Epoch 80/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3850 - accuracy: 0.8405 - val_loss: 0.4098 - val_accuracy: 0.8180\n",
      "Epoch 81/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3840 - accuracy: 0.8419 - val_loss: 0.4091 - val_accuracy: 0.8195\n",
      "Epoch 82/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3833 - accuracy: 0.8409 - val_loss: 0.4080 - val_accuracy: 0.8210\n",
      "Epoch 83/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3823 - accuracy: 0.8419 - val_loss: 0.4072 - val_accuracy: 0.8200\n",
      "Epoch 84/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3814 - accuracy: 0.8416 - val_loss: 0.4061 - val_accuracy: 0.8215\n",
      "Epoch 85/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3805 - accuracy: 0.8422 - val_loss: 0.4044 - val_accuracy: 0.8205\n",
      "Epoch 86/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3797 - accuracy: 0.8422 - val_loss: 0.4039 - val_accuracy: 0.8225\n",
      "Epoch 87/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3789 - accuracy: 0.8420 - val_loss: 0.4031 - val_accuracy: 0.8230\n",
      "Epoch 88/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3779 - accuracy: 0.8426 - val_loss: 0.4028 - val_accuracy: 0.8235\n",
      "Epoch 89/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3772 - accuracy: 0.8435 - val_loss: 0.4005 - val_accuracy: 0.8260\n",
      "Epoch 90/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3763 - accuracy: 0.8454 - val_loss: 0.3997 - val_accuracy: 0.8260\n",
      "Epoch 91/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3752 - accuracy: 0.8446 - val_loss: 0.3976 - val_accuracy: 0.8295\n",
      "Epoch 92/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3745 - accuracy: 0.8459 - val_loss: 0.3965 - val_accuracy: 0.8300\n",
      "Epoch 93/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3736 - accuracy: 0.8455 - val_loss: 0.3965 - val_accuracy: 0.8285\n",
      "Epoch 94/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3727 - accuracy: 0.8460 - val_loss: 0.3941 - val_accuracy: 0.8310\n",
      "Epoch 95/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3717 - accuracy: 0.8471 - val_loss: 0.3936 - val_accuracy: 0.8305\n",
      "Epoch 96/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3707 - accuracy: 0.8479 - val_loss: 0.3914 - val_accuracy: 0.8325\n",
      "Epoch 97/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3698 - accuracy: 0.8489 - val_loss: 0.3914 - val_accuracy: 0.8305\n",
      "Epoch 98/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3685 - accuracy: 0.8501 - val_loss: 0.3892 - val_accuracy: 0.8335\n",
      "Epoch 99/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3675 - accuracy: 0.8499 - val_loss: 0.3875 - val_accuracy: 0.8350\n",
      "Epoch 100/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3665 - accuracy: 0.8512 - val_loss: 0.3864 - val_accuracy: 0.8340\n",
      "Epoch 101/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3655 - accuracy: 0.8507 - val_loss: 0.3861 - val_accuracy: 0.8325\n",
      "Epoch 102/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3646 - accuracy: 0.8514 - val_loss: 0.3839 - val_accuracy: 0.8360\n",
      "Epoch 103/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3637 - accuracy: 0.8511 - val_loss: 0.3831 - val_accuracy: 0.8360\n",
      "Epoch 104/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3625 - accuracy: 0.8525 - val_loss: 0.3829 - val_accuracy: 0.8340\n",
      "Epoch 105/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3615 - accuracy: 0.8511 - val_loss: 0.3814 - val_accuracy: 0.8380\n",
      "Epoch 106/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3607 - accuracy: 0.8522 - val_loss: 0.3809 - val_accuracy: 0.8380\n",
      "Epoch 107/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3595 - accuracy: 0.8531 - val_loss: 0.3788 - val_accuracy: 0.8410\n",
      "Epoch 108/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3588 - accuracy: 0.8535 - val_loss: 0.3776 - val_accuracy: 0.8395\n",
      "Epoch 109/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3577 - accuracy: 0.8544 - val_loss: 0.3766 - val_accuracy: 0.8425\n",
      "Epoch 110/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3566 - accuracy: 0.8546 - val_loss: 0.3758 - val_accuracy: 0.8425\n",
      "Epoch 111/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3559 - accuracy: 0.8551 - val_loss: 0.3754 - val_accuracy: 0.8425\n",
      "Epoch 112/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3549 - accuracy: 0.8550 - val_loss: 0.3746 - val_accuracy: 0.8435\n",
      "Epoch 113/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3542 - accuracy: 0.8566 - val_loss: 0.3728 - val_accuracy: 0.8450\n",
      "Epoch 114/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3531 - accuracy: 0.8567 - val_loss: 0.3718 - val_accuracy: 0.8450\n",
      "Epoch 115/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3523 - accuracy: 0.8587 - val_loss: 0.3717 - val_accuracy: 0.8450\n",
      "Epoch 116/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3512 - accuracy: 0.8585 - val_loss: 0.3718 - val_accuracy: 0.8445\n",
      "Epoch 117/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3510 - accuracy: 0.8586 - val_loss: 0.3695 - val_accuracy: 0.8460\n",
      "Epoch 118/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3501 - accuracy: 0.8579 - val_loss: 0.3689 - val_accuracy: 0.8470\n",
      "Epoch 119/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3496 - accuracy: 0.8582 - val_loss: 0.3683 - val_accuracy: 0.8475\n",
      "Epoch 120/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3488 - accuracy: 0.8592 - val_loss: 0.3673 - val_accuracy: 0.8510\n",
      "Epoch 121/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3482 - accuracy: 0.8589 - val_loss: 0.3678 - val_accuracy: 0.8475\n",
      "Epoch 122/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3476 - accuracy: 0.8605 - val_loss: 0.3663 - val_accuracy: 0.8500\n",
      "Epoch 123/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3470 - accuracy: 0.8600 - val_loss: 0.3655 - val_accuracy: 0.8495\n",
      "Epoch 124/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3464 - accuracy: 0.8599 - val_loss: 0.3656 - val_accuracy: 0.8505\n",
      "Epoch 125/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3459 - accuracy: 0.8607 - val_loss: 0.3656 - val_accuracy: 0.8520\n",
      "Epoch 126/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3454 - accuracy: 0.8606 - val_loss: 0.3645 - val_accuracy: 0.8505\n",
      "Epoch 127/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3450 - accuracy: 0.8600 - val_loss: 0.3635 - val_accuracy: 0.8505\n",
      "Epoch 128/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3445 - accuracy: 0.8607 - val_loss: 0.3633 - val_accuracy: 0.8510\n",
      "Epoch 129/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3441 - accuracy: 0.8612 - val_loss: 0.3628 - val_accuracy: 0.8505\n",
      "Epoch 130/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3437 - accuracy: 0.8616 - val_loss: 0.3629 - val_accuracy: 0.8510\n",
      "Epoch 131/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3431 - accuracy: 0.8619 - val_loss: 0.3622 - val_accuracy: 0.8515\n",
      "Epoch 132/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3427 - accuracy: 0.8622 - val_loss: 0.3623 - val_accuracy: 0.8520\n",
      "Epoch 133/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3423 - accuracy: 0.8622 - val_loss: 0.3621 - val_accuracy: 0.8520\n",
      "Epoch 134/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3420 - accuracy: 0.8624 - val_loss: 0.3617 - val_accuracy: 0.8520\n",
      "Epoch 135/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3414 - accuracy: 0.8629 - val_loss: 0.3613 - val_accuracy: 0.8525\n",
      "Epoch 136/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3414 - accuracy: 0.8630 - val_loss: 0.3610 - val_accuracy: 0.8515\n",
      "Epoch 137/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3409 - accuracy: 0.8619 - val_loss: 0.3607 - val_accuracy: 0.8525\n",
      "Epoch 138/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3405 - accuracy: 0.8626 - val_loss: 0.3606 - val_accuracy: 0.8530\n",
      "Epoch 139/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3402 - accuracy: 0.8629 - val_loss: 0.3608 - val_accuracy: 0.8535\n",
      "Epoch 140/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3400 - accuracy: 0.8622 - val_loss: 0.3602 - val_accuracy: 0.8530\n",
      "Epoch 141/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3395 - accuracy: 0.8627 - val_loss: 0.3607 - val_accuracy: 0.8530\n",
      "Epoch 142/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3391 - accuracy: 0.8640 - val_loss: 0.3610 - val_accuracy: 0.8535\n",
      "Epoch 143/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3390 - accuracy: 0.8632 - val_loss: 0.3600 - val_accuracy: 0.8530\n",
      "Epoch 144/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3386 - accuracy: 0.8637 - val_loss: 0.3601 - val_accuracy: 0.8525\n",
      "Epoch 145/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3385 - accuracy: 0.8640 - val_loss: 0.3607 - val_accuracy: 0.8540\n",
      "Epoch 146/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3383 - accuracy: 0.8641 - val_loss: 0.3593 - val_accuracy: 0.8530\n",
      "Epoch 147/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3379 - accuracy: 0.8644 - val_loss: 0.3592 - val_accuracy: 0.8540\n",
      "Epoch 148/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3375 - accuracy: 0.8646 - val_loss: 0.3590 - val_accuracy: 0.8550\n",
      "Epoch 149/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3375 - accuracy: 0.8641 - val_loss: 0.3591 - val_accuracy: 0.8550\n",
      "Epoch 150/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3372 - accuracy: 0.8647 - val_loss: 0.3610 - val_accuracy: 0.8545\n",
      "Epoch 151/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3370 - accuracy: 0.8641 - val_loss: 0.3595 - val_accuracy: 0.8560\n",
      "Epoch 152/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3369 - accuracy: 0.8646 - val_loss: 0.3588 - val_accuracy: 0.8555\n",
      "Epoch 153/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3364 - accuracy: 0.8646 - val_loss: 0.3597 - val_accuracy: 0.8555\n",
      "Epoch 154/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3363 - accuracy: 0.8651 - val_loss: 0.3594 - val_accuracy: 0.8550\n",
      "Epoch 155/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3361 - accuracy: 0.8650 - val_loss: 0.3588 - val_accuracy: 0.8555\n",
      "Epoch 156/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3357 - accuracy: 0.8642 - val_loss: 0.3585 - val_accuracy: 0.8565\n",
      "Epoch 157/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3358 - accuracy: 0.8661 - val_loss: 0.3587 - val_accuracy: 0.8565\n",
      "Epoch 158/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3354 - accuracy: 0.8657 - val_loss: 0.3596 - val_accuracy: 0.8550\n",
      "Epoch 159/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3355 - accuracy: 0.8645 - val_loss: 0.3585 - val_accuracy: 0.8560\n",
      "Epoch 160/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3351 - accuracy: 0.8650 - val_loss: 0.3592 - val_accuracy: 0.8560\n",
      "Epoch 161/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3349 - accuracy: 0.8644 - val_loss: 0.3593 - val_accuracy: 0.8560\n",
      "Epoch 162/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3345 - accuracy: 0.8637 - val_loss: 0.3584 - val_accuracy: 0.8565\n",
      "Epoch 163/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3345 - accuracy: 0.8650 - val_loss: 0.3585 - val_accuracy: 0.8565\n",
      "Epoch 164/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3344 - accuracy: 0.8646 - val_loss: 0.3594 - val_accuracy: 0.8560\n",
      "Epoch 165/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3341 - accuracy: 0.8654 - val_loss: 0.3589 - val_accuracy: 0.8570\n",
      "Epoch 166/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3338 - accuracy: 0.8646 - val_loss: 0.3608 - val_accuracy: 0.8555\n",
      "Epoch 167/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3338 - accuracy: 0.8641 - val_loss: 0.3586 - val_accuracy: 0.8570\n",
      "Epoch 168/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3338 - accuracy: 0.8657 - val_loss: 0.3596 - val_accuracy: 0.8565\n",
      "Epoch 169/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3334 - accuracy: 0.8652 - val_loss: 0.3609 - val_accuracy: 0.8560\n",
      "Epoch 170/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3335 - accuracy: 0.8647 - val_loss: 0.3589 - val_accuracy: 0.8575\n",
      "Epoch 171/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3330 - accuracy: 0.8652 - val_loss: 0.3587 - val_accuracy: 0.8565\n",
      "Epoch 172/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3331 - accuracy: 0.8649 - val_loss: 0.3589 - val_accuracy: 0.8560\n",
      "Epoch 173/600\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.3329 - accuracy: 0.8647 - val_loss: 0.3594 - val_accuracy: 0.8555\n",
      "Epoch 174/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3328 - accuracy: 0.8651 - val_loss: 0.3583 - val_accuracy: 0.8560\n",
      "Epoch 175/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3326 - accuracy: 0.8645 - val_loss: 0.3589 - val_accuracy: 0.8580\n",
      "Epoch 176/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3325 - accuracy: 0.8647 - val_loss: 0.3587 - val_accuracy: 0.8560\n",
      "Epoch 177/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3324 - accuracy: 0.8659 - val_loss: 0.3584 - val_accuracy: 0.8555\n",
      "Epoch 178/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3320 - accuracy: 0.8661 - val_loss: 0.3593 - val_accuracy: 0.8550\n",
      "Epoch 179/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3321 - accuracy: 0.8661 - val_loss: 0.3589 - val_accuracy: 0.8535\n",
      "Epoch 180/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3320 - accuracy: 0.8662 - val_loss: 0.3588 - val_accuracy: 0.8540\n",
      "Epoch 181/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3320 - accuracy: 0.8664 - val_loss: 0.3596 - val_accuracy: 0.8565\n",
      "Epoch 182/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3315 - accuracy: 0.8652 - val_loss: 0.3603 - val_accuracy: 0.8555\n",
      "Epoch 183/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3315 - accuracy: 0.8667 - val_loss: 0.3583 - val_accuracy: 0.8555\n",
      "Epoch 184/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3314 - accuracy: 0.8662 - val_loss: 0.3582 - val_accuracy: 0.8540\n",
      "Epoch 185/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3316 - accuracy: 0.8654 - val_loss: 0.3588 - val_accuracy: 0.8535\n",
      "Epoch 186/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3313 - accuracy: 0.8664 - val_loss: 0.3586 - val_accuracy: 0.8520\n",
      "Epoch 187/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3313 - accuracy: 0.8656 - val_loss: 0.3588 - val_accuracy: 0.8535\n",
      "Epoch 188/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3310 - accuracy: 0.8659 - val_loss: 0.3595 - val_accuracy: 0.8540\n",
      "Epoch 189/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3309 - accuracy: 0.8657 - val_loss: 0.3582 - val_accuracy: 0.8550\n",
      "Epoch 190/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3308 - accuracy: 0.8661 - val_loss: 0.3594 - val_accuracy: 0.8530\n",
      "Epoch 191/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3309 - accuracy: 0.8666 - val_loss: 0.3600 - val_accuracy: 0.8535\n",
      "Epoch 192/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3305 - accuracy: 0.8652 - val_loss: 0.3583 - val_accuracy: 0.8545\n",
      "Epoch 193/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3307 - accuracy: 0.8660 - val_loss: 0.3591 - val_accuracy: 0.8525\n",
      "Epoch 194/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3305 - accuracy: 0.8666 - val_loss: 0.3590 - val_accuracy: 0.8520\n",
      "Epoch 195/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3304 - accuracy: 0.8661 - val_loss: 0.3592 - val_accuracy: 0.8535\n",
      "Epoch 196/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3303 - accuracy: 0.8669 - val_loss: 0.3592 - val_accuracy: 0.8530\n",
      "Epoch 197/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3301 - accuracy: 0.8651 - val_loss: 0.3582 - val_accuracy: 0.8540\n",
      "Epoch 198/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3299 - accuracy: 0.8662 - val_loss: 0.3591 - val_accuracy: 0.8535\n",
      "Epoch 199/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3301 - accuracy: 0.8666 - val_loss: 0.3585 - val_accuracy: 0.8540\n",
      "Epoch 200/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3298 - accuracy: 0.8667 - val_loss: 0.3583 - val_accuracy: 0.8550\n",
      "Epoch 201/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3299 - accuracy: 0.8664 - val_loss: 0.3588 - val_accuracy: 0.8535\n",
      "Epoch 202/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3298 - accuracy: 0.8650 - val_loss: 0.3585 - val_accuracy: 0.8545\n",
      "Epoch 203/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3297 - accuracy: 0.8660 - val_loss: 0.3595 - val_accuracy: 0.8535\n",
      "Epoch 204/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3297 - accuracy: 0.8665 - val_loss: 0.3591 - val_accuracy: 0.8525\n",
      "Epoch 205/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3297 - accuracy: 0.8672 - val_loss: 0.3591 - val_accuracy: 0.8540\n",
      "Epoch 206/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3295 - accuracy: 0.8661 - val_loss: 0.3598 - val_accuracy: 0.8535\n",
      "Epoch 207/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3293 - accuracy: 0.8662 - val_loss: 0.3583 - val_accuracy: 0.8555\n",
      "Epoch 208/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3295 - accuracy: 0.8664 - val_loss: 0.3586 - val_accuracy: 0.8540\n",
      "Epoch 209/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3291 - accuracy: 0.8672 - val_loss: 0.3588 - val_accuracy: 0.8545\n",
      "Epoch 210/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3293 - accuracy: 0.8669 - val_loss: 0.3586 - val_accuracy: 0.8545\n",
      "Epoch 211/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3292 - accuracy: 0.8657 - val_loss: 0.3601 - val_accuracy: 0.8500\n",
      "Epoch 212/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3293 - accuracy: 0.8665 - val_loss: 0.3591 - val_accuracy: 0.8540\n",
      "Epoch 213/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3290 - accuracy: 0.8659 - val_loss: 0.3587 - val_accuracy: 0.8545\n",
      "Epoch 214/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3290 - accuracy: 0.8662 - val_loss: 0.3586 - val_accuracy: 0.8555\n",
      "Epoch 215/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3290 - accuracy: 0.8671 - val_loss: 0.3590 - val_accuracy: 0.8550\n",
      "Epoch 216/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3290 - accuracy: 0.8669 - val_loss: 0.3591 - val_accuracy: 0.8535\n",
      "Epoch 217/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3288 - accuracy: 0.8660 - val_loss: 0.3598 - val_accuracy: 0.8525\n",
      "Epoch 218/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3288 - accuracy: 0.8671 - val_loss: 0.3595 - val_accuracy: 0.8525\n",
      "Epoch 219/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3288 - accuracy: 0.8669 - val_loss: 0.3583 - val_accuracy: 0.8535\n",
      "Epoch 220/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3287 - accuracy: 0.8676 - val_loss: 0.3597 - val_accuracy: 0.8530\n",
      "Epoch 221/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3287 - accuracy: 0.8654 - val_loss: 0.3586 - val_accuracy: 0.8540\n",
      "Epoch 222/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3286 - accuracy: 0.8662 - val_loss: 0.3580 - val_accuracy: 0.8530\n",
      "Epoch 223/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3287 - accuracy: 0.8659 - val_loss: 0.3594 - val_accuracy: 0.8540\n",
      "Epoch 224/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3284 - accuracy: 0.8666 - val_loss: 0.3601 - val_accuracy: 0.8555\n",
      "Epoch 225/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3285 - accuracy: 0.8665 - val_loss: 0.3582 - val_accuracy: 0.8540\n",
      "Epoch 226/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3283 - accuracy: 0.8661 - val_loss: 0.3583 - val_accuracy: 0.8550\n",
      "Epoch 227/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3285 - accuracy: 0.8660 - val_loss: 0.3589 - val_accuracy: 0.8550\n",
      "Epoch 228/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3283 - accuracy: 0.8662 - val_loss: 0.3578 - val_accuracy: 0.8545\n",
      "Epoch 229/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3284 - accuracy: 0.8664 - val_loss: 0.3581 - val_accuracy: 0.8540\n",
      "Epoch 230/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3282 - accuracy: 0.8662 - val_loss: 0.3579 - val_accuracy: 0.8535\n",
      "Epoch 231/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3281 - accuracy: 0.8669 - val_loss: 0.3578 - val_accuracy: 0.8540\n",
      "Epoch 232/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3282 - accuracy: 0.8666 - val_loss: 0.3576 - val_accuracy: 0.8545\n",
      "Epoch 233/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3281 - accuracy: 0.8665 - val_loss: 0.3575 - val_accuracy: 0.8540\n",
      "Epoch 234/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3284 - accuracy: 0.8665 - val_loss: 0.3577 - val_accuracy: 0.8535\n",
      "Epoch 235/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3282 - accuracy: 0.8661 - val_loss: 0.3576 - val_accuracy: 0.8535\n",
      "Epoch 236/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3280 - accuracy: 0.8662 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
      "Epoch 237/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3280 - accuracy: 0.8665 - val_loss: 0.3576 - val_accuracy: 0.8545\n",
      "Epoch 238/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3280 - accuracy: 0.8664 - val_loss: 0.3576 - val_accuracy: 0.8535\n",
      "Epoch 239/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3280 - accuracy: 0.8666 - val_loss: 0.3577 - val_accuracy: 0.8535\n",
      "Epoch 240/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3278 - accuracy: 0.8666 - val_loss: 0.3573 - val_accuracy: 0.8540\n",
      "Epoch 241/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3279 - accuracy: 0.8660 - val_loss: 0.3579 - val_accuracy: 0.8535\n",
      "Epoch 242/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3279 - accuracy: 0.8675 - val_loss: 0.3576 - val_accuracy: 0.8525\n",
      "Epoch 243/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3278 - accuracy: 0.8667 - val_loss: 0.3592 - val_accuracy: 0.8550\n",
      "Epoch 244/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3277 - accuracy: 0.8665 - val_loss: 0.3576 - val_accuracy: 0.8535\n",
      "Epoch 245/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3277 - accuracy: 0.8667 - val_loss: 0.3582 - val_accuracy: 0.8545\n",
      "Epoch 246/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3277 - accuracy: 0.8671 - val_loss: 0.3572 - val_accuracy: 0.8555\n",
      "Epoch 247/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3279 - accuracy: 0.8677 - val_loss: 0.3574 - val_accuracy: 0.8535\n",
      "Epoch 248/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3276 - accuracy: 0.8671 - val_loss: 0.3580 - val_accuracy: 0.8540\n",
      "Epoch 249/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3274 - accuracy: 0.8670 - val_loss: 0.3573 - val_accuracy: 0.8530\n",
      "Epoch 250/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3276 - accuracy: 0.8669 - val_loss: 0.3580 - val_accuracy: 0.8550\n",
      "Epoch 251/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3275 - accuracy: 0.8670 - val_loss: 0.3573 - val_accuracy: 0.8540\n",
      "Epoch 252/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3274 - accuracy: 0.8665 - val_loss: 0.3574 - val_accuracy: 0.8545\n",
      "Epoch 253/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3276 - accuracy: 0.8662 - val_loss: 0.3582 - val_accuracy: 0.8550\n",
      "Epoch 254/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3275 - accuracy: 0.8669 - val_loss: 0.3579 - val_accuracy: 0.8550\n",
      "Epoch 255/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3274 - accuracy: 0.8666 - val_loss: 0.3581 - val_accuracy: 0.8550\n",
      "Epoch 256/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3273 - accuracy: 0.8674 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 257/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3273 - accuracy: 0.8666 - val_loss: 0.3570 - val_accuracy: 0.8540\n",
      "Epoch 258/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3274 - accuracy: 0.8671 - val_loss: 0.3580 - val_accuracy: 0.8550\n",
      "Epoch 259/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3272 - accuracy: 0.8679 - val_loss: 0.3577 - val_accuracy: 0.8545\n",
      "Epoch 260/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3272 - accuracy: 0.8661 - val_loss: 0.3587 - val_accuracy: 0.8555\n",
      "Epoch 261/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3271 - accuracy: 0.8669 - val_loss: 0.3578 - val_accuracy: 0.8550\n",
      "Epoch 262/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3271 - accuracy: 0.8671 - val_loss: 0.3585 - val_accuracy: 0.8545\n",
      "Epoch 263/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3272 - accuracy: 0.8655 - val_loss: 0.3572 - val_accuracy: 0.8530\n",
      "Epoch 264/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3272 - accuracy: 0.8675 - val_loss: 0.3576 - val_accuracy: 0.8540\n",
      "Epoch 265/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3269 - accuracy: 0.8672 - val_loss: 0.3580 - val_accuracy: 0.8545\n",
      "Epoch 266/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3270 - accuracy: 0.8670 - val_loss: 0.3573 - val_accuracy: 0.8535\n",
      "Epoch 267/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3267 - accuracy: 0.8674 - val_loss: 0.3617 - val_accuracy: 0.8555\n",
      "Epoch 268/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3270 - accuracy: 0.8667 - val_loss: 0.3571 - val_accuracy: 0.8545\n",
      "Epoch 269/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3269 - accuracy: 0.8674 - val_loss: 0.3586 - val_accuracy: 0.8545\n",
      "Epoch 270/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3268 - accuracy: 0.8666 - val_loss: 0.3574 - val_accuracy: 0.8535\n",
      "Epoch 271/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3271 - accuracy: 0.8679 - val_loss: 0.3583 - val_accuracy: 0.8550\n",
      "Epoch 272/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.8671 - val_loss: 0.3590 - val_accuracy: 0.8555\n",
      "Epoch 273/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3268 - accuracy: 0.8666 - val_loss: 0.3572 - val_accuracy: 0.8555\n",
      "Epoch 274/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3269 - accuracy: 0.8684 - val_loss: 0.3572 - val_accuracy: 0.8545\n",
      "Epoch 275/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3267 - accuracy: 0.8661 - val_loss: 0.3574 - val_accuracy: 0.8535\n",
      "Epoch 276/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3267 - accuracy: 0.8670 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 277/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3269 - accuracy: 0.8670 - val_loss: 0.3577 - val_accuracy: 0.8530\n",
      "Epoch 278/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.8677 - val_loss: 0.3588 - val_accuracy: 0.8560\n",
      "Epoch 279/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3269 - accuracy: 0.8665 - val_loss: 0.3580 - val_accuracy: 0.8545\n",
      "Epoch 280/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.8679 - val_loss: 0.3572 - val_accuracy: 0.8545\n",
      "Epoch 281/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3268 - accuracy: 0.8670 - val_loss: 0.3580 - val_accuracy: 0.8545\n",
      "Epoch 282/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3267 - accuracy: 0.8662 - val_loss: 0.3575 - val_accuracy: 0.8550\n",
      "Epoch 283/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3265 - accuracy: 0.8674 - val_loss: 0.3585 - val_accuracy: 0.8560\n",
      "Epoch 284/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.8666 - val_loss: 0.3571 - val_accuracy: 0.8545\n",
      "Epoch 285/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3265 - accuracy: 0.8681 - val_loss: 0.3587 - val_accuracy: 0.8570\n",
      "Epoch 286/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3268 - accuracy: 0.8669 - val_loss: 0.3581 - val_accuracy: 0.8535\n",
      "Epoch 287/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3263 - accuracy: 0.8675 - val_loss: 0.3589 - val_accuracy: 0.8560\n",
      "Epoch 288/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.8676 - val_loss: 0.3593 - val_accuracy: 0.8565\n",
      "Epoch 289/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3266 - accuracy: 0.8675 - val_loss: 0.3586 - val_accuracy: 0.8555\n",
      "Epoch 290/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3263 - accuracy: 0.8682 - val_loss: 0.3578 - val_accuracy: 0.8540\n",
      "Epoch 291/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3264 - accuracy: 0.8665 - val_loss: 0.3584 - val_accuracy: 0.8545\n",
      "Epoch 292/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3263 - accuracy: 0.8674 - val_loss: 0.3574 - val_accuracy: 0.8545\n",
      "Epoch 293/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3263 - accuracy: 0.8674 - val_loss: 0.3574 - val_accuracy: 0.8550\n",
      "Epoch 294/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3264 - accuracy: 0.8677 - val_loss: 0.3571 - val_accuracy: 0.8530\n",
      "Epoch 295/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3262 - accuracy: 0.8674 - val_loss: 0.3574 - val_accuracy: 0.8520\n",
      "Epoch 296/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3265 - accuracy: 0.8661 - val_loss: 0.3587 - val_accuracy: 0.8565\n",
      "Epoch 297/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3264 - accuracy: 0.8675 - val_loss: 0.3581 - val_accuracy: 0.8555\n",
      "Epoch 298/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3263 - accuracy: 0.8680 - val_loss: 0.3585 - val_accuracy: 0.8555\n",
      "Epoch 299/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3262 - accuracy: 0.8672 - val_loss: 0.3575 - val_accuracy: 0.8540\n",
      "Epoch 300/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3263 - accuracy: 0.8679 - val_loss: 0.3575 - val_accuracy: 0.8545\n",
      "Epoch 301/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3262 - accuracy: 0.8672 - val_loss: 0.3572 - val_accuracy: 0.8545\n",
      "Epoch 302/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3260 - accuracy: 0.8667 - val_loss: 0.3573 - val_accuracy: 0.8545\n",
      "Epoch 303/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3262 - accuracy: 0.8665 - val_loss: 0.3571 - val_accuracy: 0.8545\n",
      "Epoch 304/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3263 - accuracy: 0.8659 - val_loss: 0.3571 - val_accuracy: 0.8540\n",
      "Epoch 305/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3262 - accuracy: 0.8671 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 306/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3260 - accuracy: 0.8664 - val_loss: 0.3572 - val_accuracy: 0.8540\n",
      "Epoch 307/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3261 - accuracy: 0.8670 - val_loss: 0.3588 - val_accuracy: 0.8560\n",
      "Epoch 308/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3261 - accuracy: 0.8672 - val_loss: 0.3572 - val_accuracy: 0.8540\n",
      "Epoch 309/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3262 - accuracy: 0.8666 - val_loss: 0.3578 - val_accuracy: 0.8545\n",
      "Epoch 310/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3259 - accuracy: 0.8670 - val_loss: 0.3584 - val_accuracy: 0.8560\n",
      "Epoch 311/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3256 - accuracy: 0.8667 - val_loss: 0.3575 - val_accuracy: 0.8555\n",
      "Epoch 312/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3260 - accuracy: 0.8669 - val_loss: 0.3577 - val_accuracy: 0.8540\n",
      "Epoch 313/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8676 - val_loss: 0.3587 - val_accuracy: 0.8570\n",
      "Epoch 314/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8670 - val_loss: 0.3571 - val_accuracy: 0.8535\n",
      "Epoch 315/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3261 - accuracy: 0.8672 - val_loss: 0.3579 - val_accuracy: 0.8565\n",
      "Epoch 316/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8675 - val_loss: 0.3580 - val_accuracy: 0.8555\n",
      "Epoch 317/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3257 - accuracy: 0.8671 - val_loss: 0.3572 - val_accuracy: 0.8535\n",
      "Epoch 318/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3259 - accuracy: 0.8675 - val_loss: 0.3573 - val_accuracy: 0.8545\n",
      "Epoch 319/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3253 - accuracy: 0.8671 - val_loss: 0.3587 - val_accuracy: 0.8560\n",
      "Epoch 320/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8667 - val_loss: 0.3586 - val_accuracy: 0.8555\n",
      "Epoch 321/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3255 - accuracy: 0.8677 - val_loss: 0.3573 - val_accuracy: 0.8500\n",
      "Epoch 322/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8677 - val_loss: 0.3577 - val_accuracy: 0.8555\n",
      "Epoch 323/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8676 - val_loss: 0.3579 - val_accuracy: 0.8560\n",
      "Epoch 324/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8675 - val_loss: 0.3584 - val_accuracy: 0.8570\n",
      "Epoch 325/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3258 - accuracy: 0.8656 - val_loss: 0.3591 - val_accuracy: 0.8570\n",
      "Epoch 326/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3257 - accuracy: 0.8681 - val_loss: 0.3575 - val_accuracy: 0.8545\n",
      "Epoch 327/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3257 - accuracy: 0.8665 - val_loss: 0.3580 - val_accuracy: 0.8560\n",
      "Epoch 328/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3256 - accuracy: 0.8674 - val_loss: 0.3576 - val_accuracy: 0.8565\n",
      "Epoch 329/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3256 - accuracy: 0.8667 - val_loss: 0.3582 - val_accuracy: 0.8565\n",
      "Epoch 330/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3255 - accuracy: 0.8670 - val_loss: 0.3575 - val_accuracy: 0.8560\n",
      "Epoch 331/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3254 - accuracy: 0.8670 - val_loss: 0.3581 - val_accuracy: 0.8560\n",
      "Epoch 332/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3255 - accuracy: 0.8674 - val_loss: 0.3574 - val_accuracy: 0.8560\n",
      "Epoch 333/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3254 - accuracy: 0.8681 - val_loss: 0.3573 - val_accuracy: 0.8555\n",
      "Epoch 334/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3255 - accuracy: 0.8669 - val_loss: 0.3583 - val_accuracy: 0.8565\n",
      "Epoch 335/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3256 - accuracy: 0.8667 - val_loss: 0.3572 - val_accuracy: 0.8550\n",
      "Epoch 336/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3253 - accuracy: 0.8667 - val_loss: 0.3571 - val_accuracy: 0.8520\n",
      "Epoch 337/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3256 - accuracy: 0.8680 - val_loss: 0.3571 - val_accuracy: 0.8540\n",
      "Epoch 338/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3253 - accuracy: 0.8681 - val_loss: 0.3584 - val_accuracy: 0.8570\n",
      "Epoch 339/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3253 - accuracy: 0.8670 - val_loss: 0.3599 - val_accuracy: 0.8555\n",
      "Epoch 340/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3255 - accuracy: 0.8672 - val_loss: 0.3585 - val_accuracy: 0.8565\n",
      "Epoch 341/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3252 - accuracy: 0.8675 - val_loss: 0.3572 - val_accuracy: 0.8530\n",
      "Epoch 342/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3253 - accuracy: 0.8680 - val_loss: 0.3573 - val_accuracy: 0.8550\n",
      "Epoch 343/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3252 - accuracy: 0.8674 - val_loss: 0.3581 - val_accuracy: 0.8560\n",
      "Epoch 344/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3252 - accuracy: 0.8672 - val_loss: 0.3599 - val_accuracy: 0.8560\n",
      "Epoch 345/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3252 - accuracy: 0.8671 - val_loss: 0.3589 - val_accuracy: 0.8555\n",
      "Epoch 346/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3252 - accuracy: 0.8664 - val_loss: 0.3581 - val_accuracy: 0.8550\n",
      "Epoch 347/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3250 - accuracy: 0.8674 - val_loss: 0.3576 - val_accuracy: 0.8540\n",
      "Epoch 348/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3251 - accuracy: 0.8659 - val_loss: 0.3597 - val_accuracy: 0.8565\n",
      "Epoch 349/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3252 - accuracy: 0.8674 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 350/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3250 - accuracy: 0.8664 - val_loss: 0.3574 - val_accuracy: 0.8545\n",
      "Epoch 351/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3250 - accuracy: 0.8670 - val_loss: 0.3578 - val_accuracy: 0.8545\n",
      "Epoch 352/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3250 - accuracy: 0.8674 - val_loss: 0.3579 - val_accuracy: 0.8550\n",
      "Epoch 353/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3250 - accuracy: 0.8676 - val_loss: 0.3574 - val_accuracy: 0.8550\n",
      "Epoch 354/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3248 - accuracy: 0.8672 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 355/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3250 - accuracy: 0.8674 - val_loss: 0.3583 - val_accuracy: 0.8545\n",
      "Epoch 356/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3248 - accuracy: 0.8669 - val_loss: 0.3569 - val_accuracy: 0.8530\n",
      "Epoch 357/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3251 - accuracy: 0.8661 - val_loss: 0.3596 - val_accuracy: 0.8565\n",
      "Epoch 358/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3249 - accuracy: 0.8682 - val_loss: 0.3579 - val_accuracy: 0.8535\n",
      "Epoch 359/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3249 - accuracy: 0.8671 - val_loss: 0.3569 - val_accuracy: 0.8515\n",
      "Epoch 360/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3247 - accuracy: 0.8676 - val_loss: 0.3574 - val_accuracy: 0.8550\n",
      "Epoch 361/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3243 - accuracy: 0.8671 - val_loss: 0.3587 - val_accuracy: 0.8565\n",
      "Epoch 362/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3247 - accuracy: 0.8682 - val_loss: 0.3587 - val_accuracy: 0.8560\n",
      "Epoch 363/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3245 - accuracy: 0.8682 - val_loss: 0.3570 - val_accuracy: 0.8515\n",
      "Epoch 364/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3247 - accuracy: 0.8671 - val_loss: 0.3578 - val_accuracy: 0.8540\n",
      "Epoch 365/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3245 - accuracy: 0.8674 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 366/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3246 - accuracy: 0.8680 - val_loss: 0.3581 - val_accuracy: 0.8535\n",
      "Epoch 367/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3245 - accuracy: 0.8672 - val_loss: 0.3582 - val_accuracy: 0.8550\n",
      "Epoch 368/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3246 - accuracy: 0.8670 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 369/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3246 - accuracy: 0.8675 - val_loss: 0.3566 - val_accuracy: 0.8520\n",
      "Epoch 370/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3245 - accuracy: 0.8671 - val_loss: 0.3576 - val_accuracy: 0.8535\n",
      "Epoch 371/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3244 - accuracy: 0.8681 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
      "Epoch 372/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8670 - val_loss: 0.3586 - val_accuracy: 0.8570\n",
      "Epoch 373/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3241 - accuracy: 0.8666 - val_loss: 0.3566 - val_accuracy: 0.8505\n",
      "Epoch 374/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8686 - val_loss: 0.3575 - val_accuracy: 0.8520\n",
      "Epoch 375/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3245 - accuracy: 0.8674 - val_loss: 0.3570 - val_accuracy: 0.8525\n",
      "Epoch 376/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3244 - accuracy: 0.8682 - val_loss: 0.3579 - val_accuracy: 0.8535\n",
      "Epoch 377/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8667 - val_loss: 0.3573 - val_accuracy: 0.8520\n",
      "Epoch 378/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3244 - accuracy: 0.8674 - val_loss: 0.3568 - val_accuracy: 0.8505\n",
      "Epoch 379/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3241 - accuracy: 0.8684 - val_loss: 0.3577 - val_accuracy: 0.8530\n",
      "Epoch 380/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3241 - accuracy: 0.8685 - val_loss: 0.3567 - val_accuracy: 0.8515\n",
      "Epoch 381/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8684 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
      "Epoch 382/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8674 - val_loss: 0.3565 - val_accuracy: 0.8510\n",
      "Epoch 383/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8682 - val_loss: 0.3576 - val_accuracy: 0.8545\n",
      "Epoch 384/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3239 - accuracy: 0.8680 - val_loss: 0.3568 - val_accuracy: 0.8500\n",
      "Epoch 385/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8670 - val_loss: 0.3567 - val_accuracy: 0.8515\n",
      "Epoch 386/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3240 - accuracy: 0.8675 - val_loss: 0.3583 - val_accuracy: 0.8560\n",
      "Epoch 387/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3241 - accuracy: 0.8680 - val_loss: 0.3602 - val_accuracy: 0.8555\n",
      "Epoch 388/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3241 - accuracy: 0.8677 - val_loss: 0.3566 - val_accuracy: 0.8535\n",
      "Epoch 389/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8676 - val_loss: 0.3568 - val_accuracy: 0.8525\n",
      "Epoch 390/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8685 - val_loss: 0.3603 - val_accuracy: 0.8555\n",
      "Epoch 391/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3239 - accuracy: 0.8681 - val_loss: 0.3572 - val_accuracy: 0.8515\n",
      "Epoch 392/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3239 - accuracy: 0.8692 - val_loss: 0.3597 - val_accuracy: 0.8555\n",
      "Epoch 393/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3238 - accuracy: 0.8679 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 394/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3241 - accuracy: 0.8672 - val_loss: 0.3581 - val_accuracy: 0.8535\n",
      "Epoch 395/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3239 - accuracy: 0.8675 - val_loss: 0.3569 - val_accuracy: 0.8535\n",
      "Epoch 396/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8679 - val_loss: 0.3588 - val_accuracy: 0.8560\n",
      "Epoch 397/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3239 - accuracy: 0.8674 - val_loss: 0.3569 - val_accuracy: 0.8525\n",
      "Epoch 398/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3240 - accuracy: 0.8681 - val_loss: 0.3572 - val_accuracy: 0.8540\n",
      "Epoch 399/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3238 - accuracy: 0.8680 - val_loss: 0.3570 - val_accuracy: 0.8550\n",
      "Epoch 400/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8666 - val_loss: 0.3594 - val_accuracy: 0.8555\n",
      "Epoch 401/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3238 - accuracy: 0.8677 - val_loss: 0.3572 - val_accuracy: 0.8525\n",
      "Epoch 402/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8685 - val_loss: 0.3579 - val_accuracy: 0.8555\n",
      "Epoch 403/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8684 - val_loss: 0.3570 - val_accuracy: 0.8530\n",
      "Epoch 404/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8671 - val_loss: 0.3566 - val_accuracy: 0.8505\n",
      "Epoch 405/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8666 - val_loss: 0.3586 - val_accuracy: 0.8555\n",
      "Epoch 406/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8679 - val_loss: 0.3567 - val_accuracy: 0.8515\n",
      "Epoch 407/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8674 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 408/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3239 - accuracy: 0.8677 - val_loss: 0.3578 - val_accuracy: 0.8530\n",
      "Epoch 409/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8682 - val_loss: 0.3576 - val_accuracy: 0.8520\n",
      "Epoch 410/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8684 - val_loss: 0.3573 - val_accuracy: 0.8510\n",
      "Epoch 411/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8680 - val_loss: 0.3569 - val_accuracy: 0.8520\n",
      "Epoch 412/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3237 - accuracy: 0.8675 - val_loss: 0.3575 - val_accuracy: 0.8510\n",
      "Epoch 413/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3235 - accuracy: 0.8685 - val_loss: 0.3583 - val_accuracy: 0.8545\n",
      "Epoch 414/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8681 - val_loss: 0.3569 - val_accuracy: 0.8520\n",
      "Epoch 415/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8671 - val_loss: 0.3569 - val_accuracy: 0.8520\n",
      "Epoch 416/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8684 - val_loss: 0.3574 - val_accuracy: 0.8525\n",
      "Epoch 417/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8676 - val_loss: 0.3586 - val_accuracy: 0.8535\n",
      "Epoch 418/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3235 - accuracy: 0.8694 - val_loss: 0.3568 - val_accuracy: 0.8510\n",
      "Epoch 419/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8684 - val_loss: 0.3600 - val_accuracy: 0.8555\n",
      "Epoch 420/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8685 - val_loss: 0.3573 - val_accuracy: 0.8495\n",
      "Epoch 421/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8677 - val_loss: 0.3567 - val_accuracy: 0.8500\n",
      "Epoch 422/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8682 - val_loss: 0.3573 - val_accuracy: 0.8520\n",
      "Epoch 423/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3235 - accuracy: 0.8680 - val_loss: 0.3572 - val_accuracy: 0.8525\n",
      "Epoch 424/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8685 - val_loss: 0.3570 - val_accuracy: 0.8525\n",
      "Epoch 425/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8686 - val_loss: 0.3574 - val_accuracy: 0.8535\n",
      "Epoch 426/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8679 - val_loss: 0.3576 - val_accuracy: 0.8545\n",
      "Epoch 427/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8681 - val_loss: 0.3566 - val_accuracy: 0.8525\n",
      "Epoch 428/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8674 - val_loss: 0.3584 - val_accuracy: 0.8535\n",
      "Epoch 429/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8686 - val_loss: 0.3572 - val_accuracy: 0.8500\n",
      "Epoch 430/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8681 - val_loss: 0.3579 - val_accuracy: 0.8520\n",
      "Epoch 431/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8684 - val_loss: 0.3581 - val_accuracy: 0.8535\n",
      "Epoch 432/600\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.3234 - accuracy: 0.8679 - val_loss: 0.3569 - val_accuracy: 0.8530\n",
      "Epoch 433/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3236 - accuracy: 0.8671 - val_loss: 0.3571 - val_accuracy: 0.8530\n",
      "Epoch 434/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8672 - val_loss: 0.3586 - val_accuracy: 0.8520\n",
      "Epoch 435/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8684 - val_loss: 0.3570 - val_accuracy: 0.8525\n",
      "Epoch 436/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3233 - accuracy: 0.8670 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 437/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8671 - val_loss: 0.3573 - val_accuracy: 0.8530\n",
      "Epoch 438/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3234 - accuracy: 0.8679 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 439/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3232 - accuracy: 0.8676 - val_loss: 0.3569 - val_accuracy: 0.8505\n",
      "Epoch 440/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8681 - val_loss: 0.3580 - val_accuracy: 0.8515\n",
      "Epoch 441/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3232 - accuracy: 0.8675 - val_loss: 0.3568 - val_accuracy: 0.8515\n",
      "Epoch 442/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3232 - accuracy: 0.8680 - val_loss: 0.3564 - val_accuracy: 0.8510\n",
      "Epoch 443/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8679 - val_loss: 0.3574 - val_accuracy: 0.8515\n",
      "Epoch 444/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8682 - val_loss: 0.3574 - val_accuracy: 0.8525\n",
      "Epoch 445/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8681 - val_loss: 0.3565 - val_accuracy: 0.8510\n",
      "Epoch 446/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8684 - val_loss: 0.3577 - val_accuracy: 0.8535\n",
      "Epoch 447/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8675 - val_loss: 0.3569 - val_accuracy: 0.8520\n",
      "Epoch 448/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3232 - accuracy: 0.8675 - val_loss: 0.3567 - val_accuracy: 0.8530\n",
      "Epoch 449/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8685 - val_loss: 0.3569 - val_accuracy: 0.8525\n",
      "Epoch 450/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8680 - val_loss: 0.3566 - val_accuracy: 0.8505\n",
      "Epoch 451/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8675 - val_loss: 0.3590 - val_accuracy: 0.8540\n",
      "Epoch 452/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8675 - val_loss: 0.3569 - val_accuracy: 0.8515\n",
      "Epoch 453/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8687 - val_loss: 0.3579 - val_accuracy: 0.8555\n",
      "Epoch 454/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3232 - accuracy: 0.8679 - val_loss: 0.3571 - val_accuracy: 0.8525\n",
      "Epoch 455/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8684 - val_loss: 0.3584 - val_accuracy: 0.8510\n",
      "Epoch 456/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3229 - accuracy: 0.8676 - val_loss: 0.3567 - val_accuracy: 0.8515\n",
      "Epoch 457/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8680 - val_loss: 0.3568 - val_accuracy: 0.8525\n",
      "Epoch 458/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8689 - val_loss: 0.3564 - val_accuracy: 0.8525\n",
      "Epoch 459/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3229 - accuracy: 0.8692 - val_loss: 0.3570 - val_accuracy: 0.8535\n",
      "Epoch 460/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8667 - val_loss: 0.3572 - val_accuracy: 0.8515\n",
      "Epoch 461/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8675 - val_loss: 0.3584 - val_accuracy: 0.8525\n",
      "Epoch 462/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8676 - val_loss: 0.3579 - val_accuracy: 0.8510\n",
      "Epoch 463/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8682 - val_loss: 0.3581 - val_accuracy: 0.8555\n",
      "Epoch 464/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8685 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 465/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3229 - accuracy: 0.8671 - val_loss: 0.3568 - val_accuracy: 0.8525\n",
      "Epoch 466/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8680 - val_loss: 0.3592 - val_accuracy: 0.8545\n",
      "Epoch 467/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3229 - accuracy: 0.8682 - val_loss: 0.3573 - val_accuracy: 0.8530\n",
      "Epoch 468/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3229 - accuracy: 0.8680 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 469/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8692 - val_loss: 0.3598 - val_accuracy: 0.8540\n",
      "Epoch 470/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3230 - accuracy: 0.8677 - val_loss: 0.3568 - val_accuracy: 0.8505\n",
      "Epoch 471/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3229 - accuracy: 0.8689 - val_loss: 0.3574 - val_accuracy: 0.8515\n",
      "Epoch 472/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3231 - accuracy: 0.8685 - val_loss: 0.3569 - val_accuracy: 0.8515\n",
      "Epoch 473/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8675 - val_loss: 0.3582 - val_accuracy: 0.8515\n",
      "Epoch 474/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8686 - val_loss: 0.3570 - val_accuracy: 0.8525\n",
      "Epoch 475/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8687 - val_loss: 0.3588 - val_accuracy: 0.8535\n",
      "Epoch 476/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8681 - val_loss: 0.3583 - val_accuracy: 0.8525\n",
      "Epoch 477/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8681 - val_loss: 0.3567 - val_accuracy: 0.8535\n",
      "Epoch 478/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8695 - val_loss: 0.3598 - val_accuracy: 0.8540\n",
      "Epoch 479/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8687 - val_loss: 0.3577 - val_accuracy: 0.8530\n",
      "Epoch 480/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8686 - val_loss: 0.3573 - val_accuracy: 0.8520\n",
      "Epoch 481/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8690 - val_loss: 0.3594 - val_accuracy: 0.8540\n",
      "Epoch 482/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8677 - val_loss: 0.3574 - val_accuracy: 0.8520\n",
      "Epoch 483/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8677 - val_loss: 0.3577 - val_accuracy: 0.8555\n",
      "Epoch 484/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8684 - val_loss: 0.3568 - val_accuracy: 0.8515\n",
      "Epoch 485/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8679 - val_loss: 0.3590 - val_accuracy: 0.8545\n",
      "Epoch 486/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8690 - val_loss: 0.3580 - val_accuracy: 0.8530\n",
      "Epoch 487/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8685 - val_loss: 0.3580 - val_accuracy: 0.8545\n",
      "Epoch 488/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3228 - accuracy: 0.8681 - val_loss: 0.3571 - val_accuracy: 0.8520\n",
      "Epoch 489/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8685 - val_loss: 0.3577 - val_accuracy: 0.8530\n",
      "Epoch 490/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8686 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 491/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8685 - val_loss: 0.3567 - val_accuracy: 0.8535\n",
      "Epoch 492/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8680 - val_loss: 0.3576 - val_accuracy: 0.8510\n",
      "Epoch 493/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8692 - val_loss: 0.3581 - val_accuracy: 0.8520\n",
      "Epoch 494/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8682 - val_loss: 0.3564 - val_accuracy: 0.8525\n",
      "Epoch 495/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8686 - val_loss: 0.3581 - val_accuracy: 0.8515\n",
      "Epoch 496/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8679 - val_loss: 0.3567 - val_accuracy: 0.8545\n",
      "Epoch 497/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8676 - val_loss: 0.3569 - val_accuracy: 0.8530\n",
      "Epoch 498/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8689 - val_loss: 0.3579 - val_accuracy: 0.8525\n",
      "Epoch 499/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8685 - val_loss: 0.3564 - val_accuracy: 0.8520\n",
      "Epoch 500/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8679 - val_loss: 0.3568 - val_accuracy: 0.8530\n",
      "Epoch 501/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8681 - val_loss: 0.3582 - val_accuracy: 0.8530\n",
      "Epoch 502/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8682 - val_loss: 0.3568 - val_accuracy: 0.8495\n",
      "Epoch 503/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8684 - val_loss: 0.3567 - val_accuracy: 0.8520\n",
      "Epoch 504/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8684 - val_loss: 0.3568 - val_accuracy: 0.8515\n",
      "Epoch 505/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8679 - val_loss: 0.3587 - val_accuracy: 0.8550\n",
      "Epoch 506/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3227 - accuracy: 0.8690 - val_loss: 0.3587 - val_accuracy: 0.8525\n",
      "Epoch 507/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8690 - val_loss: 0.3567 - val_accuracy: 0.8510\n",
      "Epoch 508/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8687 - val_loss: 0.3571 - val_accuracy: 0.8520\n",
      "Epoch 509/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8672 - val_loss: 0.3571 - val_accuracy: 0.8520\n",
      "Epoch 510/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8690 - val_loss: 0.3567 - val_accuracy: 0.8520\n",
      "Epoch 511/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8689 - val_loss: 0.3576 - val_accuracy: 0.8535\n",
      "Epoch 512/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8679 - val_loss: 0.3591 - val_accuracy: 0.8530\n",
      "Epoch 513/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8676 - val_loss: 0.3589 - val_accuracy: 0.8505\n",
      "Epoch 514/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8686 - val_loss: 0.3570 - val_accuracy: 0.8545\n",
      "Epoch 515/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3226 - accuracy: 0.8674 - val_loss: 0.3570 - val_accuracy: 0.8520\n",
      "Epoch 516/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8680 - val_loss: 0.3566 - val_accuracy: 0.8530\n",
      "Epoch 517/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8682 - val_loss: 0.3582 - val_accuracy: 0.8515\n",
      "Epoch 518/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8674 - val_loss: 0.3577 - val_accuracy: 0.8525\n",
      "Epoch 519/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8682 - val_loss: 0.3588 - val_accuracy: 0.8545\n",
      "Epoch 520/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8677 - val_loss: 0.3569 - val_accuracy: 0.8540\n",
      "Epoch 521/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8684 - val_loss: 0.3569 - val_accuracy: 0.8525\n",
      "Epoch 522/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8689 - val_loss: 0.3569 - val_accuracy: 0.8520\n",
      "Epoch 523/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8684 - val_loss: 0.3573 - val_accuracy: 0.8540\n",
      "Epoch 524/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8690 - val_loss: 0.3577 - val_accuracy: 0.8525\n",
      "Epoch 525/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8682 - val_loss: 0.3569 - val_accuracy: 0.8520\n",
      "Epoch 526/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8674 - val_loss: 0.3579 - val_accuracy: 0.8520\n",
      "Epoch 527/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8679 - val_loss: 0.3580 - val_accuracy: 0.8520\n",
      "Epoch 528/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8671 - val_loss: 0.3581 - val_accuracy: 0.8525\n",
      "Epoch 529/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8681 - val_loss: 0.3568 - val_accuracy: 0.8510\n",
      "Epoch 530/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3225 - accuracy: 0.8674 - val_loss: 0.3569 - val_accuracy: 0.8520\n",
      "Epoch 531/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8682 - val_loss: 0.3567 - val_accuracy: 0.8525\n",
      "Epoch 532/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8686 - val_loss: 0.3568 - val_accuracy: 0.8515\n",
      "Epoch 533/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8680 - val_loss: 0.3589 - val_accuracy: 0.8515\n",
      "Epoch 534/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8685 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 535/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8689 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 536/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8689 - val_loss: 0.3586 - val_accuracy: 0.8525\n",
      "Epoch 537/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8686 - val_loss: 0.3587 - val_accuracy: 0.8540\n",
      "Epoch 538/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8680 - val_loss: 0.3574 - val_accuracy: 0.8540\n",
      "Epoch 539/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8681 - val_loss: 0.3576 - val_accuracy: 0.8525\n",
      "Epoch 540/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8674 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 541/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8689 - val_loss: 0.3570 - val_accuracy: 0.8530\n",
      "Epoch 542/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8690 - val_loss: 0.3585 - val_accuracy: 0.8530\n",
      "Epoch 543/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8685 - val_loss: 0.3572 - val_accuracy: 0.8545\n",
      "Epoch 544/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8689 - val_loss: 0.3580 - val_accuracy: 0.8530\n",
      "Epoch 545/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8684 - val_loss: 0.3571 - val_accuracy: 0.8520\n",
      "Epoch 546/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3224 - accuracy: 0.8687 - val_loss: 0.3584 - val_accuracy: 0.8535\n",
      "Epoch 547/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8689 - val_loss: 0.3588 - val_accuracy: 0.8530\n",
      "Epoch 548/600\n",
      "500/500 [==============================] - 3s 7ms/step - loss: 0.3222 - accuracy: 0.8680 - val_loss: 0.3580 - val_accuracy: 0.8530\n",
      "Epoch 549/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8684 - val_loss: 0.3579 - val_accuracy: 0.8520\n",
      "Epoch 550/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8684 - val_loss: 0.3574 - val_accuracy: 0.8530\n",
      "Epoch 551/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8682 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 552/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3217 - accuracy: 0.8675 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 553/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8677 - val_loss: 0.3571 - val_accuracy: 0.8515\n",
      "Epoch 554/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8682 - val_loss: 0.3590 - val_accuracy: 0.8515\n",
      "Epoch 555/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8680 - val_loss: 0.3575 - val_accuracy: 0.8535\n",
      "Epoch 556/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8676 - val_loss: 0.3581 - val_accuracy: 0.8530\n",
      "Epoch 557/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8685 - val_loss: 0.3581 - val_accuracy: 0.8520\n",
      "Epoch 558/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8690 - val_loss: 0.3577 - val_accuracy: 0.8525\n",
      "Epoch 559/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8680 - val_loss: 0.3573 - val_accuracy: 0.8540\n",
      "Epoch 560/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8676 - val_loss: 0.3573 - val_accuracy: 0.8530\n",
      "Epoch 561/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8687 - val_loss: 0.3572 - val_accuracy: 0.8530\n",
      "Epoch 562/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3222 - accuracy: 0.8684 - val_loss: 0.3575 - val_accuracy: 0.8530\n",
      "Epoch 563/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8687 - val_loss: 0.3587 - val_accuracy: 0.8530\n",
      "Epoch 564/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8696 - val_loss: 0.3586 - val_accuracy: 0.8520\n",
      "Epoch 565/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8684 - val_loss: 0.3573 - val_accuracy: 0.8530\n",
      "Epoch 566/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3223 - accuracy: 0.8679 - val_loss: 0.3576 - val_accuracy: 0.8530\n",
      "Epoch 567/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8679 - val_loss: 0.3575 - val_accuracy: 0.8525\n",
      "Epoch 568/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8691 - val_loss: 0.3574 - val_accuracy: 0.8525\n",
      "Epoch 569/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8691 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 570/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8685 - val_loss: 0.3581 - val_accuracy: 0.8530\n",
      "Epoch 571/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8681 - val_loss: 0.3591 - val_accuracy: 0.8530\n",
      "Epoch 572/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8681 - val_loss: 0.3573 - val_accuracy: 0.8525\n",
      "Epoch 573/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8685 - val_loss: 0.3587 - val_accuracy: 0.8520\n",
      "Epoch 574/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8687 - val_loss: 0.3591 - val_accuracy: 0.8515\n",
      "Epoch 575/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8682 - val_loss: 0.3576 - val_accuracy: 0.8540\n",
      "Epoch 576/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8687 - val_loss: 0.3578 - val_accuracy: 0.8530\n",
      "Epoch 577/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8680 - val_loss: 0.3578 - val_accuracy: 0.8530\n",
      "Epoch 578/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8689 - val_loss: 0.3575 - val_accuracy: 0.8530\n",
      "Epoch 579/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3217 - accuracy: 0.8684 - val_loss: 0.3577 - val_accuracy: 0.8540\n",
      "Epoch 580/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8685 - val_loss: 0.3586 - val_accuracy: 0.8515\n",
      "Epoch 581/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8685 - val_loss: 0.3575 - val_accuracy: 0.8530\n",
      "Epoch 582/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8687 - val_loss: 0.3577 - val_accuracy: 0.8530\n",
      "Epoch 583/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8690 - val_loss: 0.3576 - val_accuracy: 0.8540\n",
      "Epoch 584/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8677 - val_loss: 0.3579 - val_accuracy: 0.8525\n",
      "Epoch 585/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8692 - val_loss: 0.3575 - val_accuracy: 0.8535\n",
      "Epoch 586/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8691 - val_loss: 0.3577 - val_accuracy: 0.8535\n",
      "Epoch 587/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8680 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
      "Epoch 588/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8689 - val_loss: 0.3578 - val_accuracy: 0.8525\n",
      "Epoch 589/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3220 - accuracy: 0.8689 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 590/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8695 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
      "Epoch 591/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3221 - accuracy: 0.8696 - val_loss: 0.3593 - val_accuracy: 0.8525\n",
      "Epoch 592/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8684 - val_loss: 0.3578 - val_accuracy: 0.8535\n",
      "Epoch 593/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8685 - val_loss: 0.3581 - val_accuracy: 0.8530\n",
      "Epoch 594/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3216 - accuracy: 0.8689 - val_loss: 0.3590 - val_accuracy: 0.8520\n",
      "Epoch 595/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3219 - accuracy: 0.8682 - val_loss: 0.3577 - val_accuracy: 0.8530\n",
      "Epoch 596/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3217 - accuracy: 0.8696 - val_loss: 0.3575 - val_accuracy: 0.8550\n",
      "Epoch 597/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3216 - accuracy: 0.8681 - val_loss: 0.3590 - val_accuracy: 0.8515\n",
      "Epoch 598/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3216 - accuracy: 0.8691 - val_loss: 0.3573 - val_accuracy: 0.8515\n",
      "Epoch 599/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3217 - accuracy: 0.8692 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 600/600\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.3218 - accuracy: 0.8685 - val_loss: 0.3581 - val_accuracy: 0.8520\n"
     ]
    }
   ],
   "source": [
    "model = ann.fit(\n",
    "    x_train, y_train, \n",
    "    batch_size = 16, \n",
    "    epochs= 600,\n",
    "    validation_data = (x_test, y_test)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 85.200006%\n"
     ]
    }
   ],
   "source": [
    "scores = ann.evaluate(x_test, y_test, verbose = 0)\n",
    "print(\"Accuracy : %2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model accuracy \n",
    "plt.plot(model.history['accuracy'])\n",
    "plt.plot(model.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#model loss\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict if the following customer will leave the bank:\n",
    "\n",
    "- Geography: France\n",
    "- Credit Score: 600\n",
    "- Gender: Male\n",
    "- Age: 40\n",
    "- Tenure: 3 \n",
    "- Balance: 60000\n",
    "- Num of Products: 2\n",
    "- Has Credit Card: Yes\n",
    "- Active Member: Yes\n",
    "- Est Salary: 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = [1.0, 0.0, 1.0,600,1,40,3,60000,2,1,1,50000]\n",
    "\n",
    "ann.predict(ss.transform([pred])) > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sigmoid threshold\n",
    "y_pred = ann.predict(x_test) > 0.5\n",
    "\n",
    "#reshaping y test and predict\n",
    "y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "y_test = y_test.reshape(len(y_test), 1)\n",
    "\n",
    "#predicted accuracy\n",
    "np.count_nonzero((y_test == y_pred) == True) / len(y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1493   84]\n",
      " [ 212  211]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ab04e040a433bf6ba14ba60baa9fe8a73464c83ea387043b6cfefa471b56ce5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('udemy-ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
